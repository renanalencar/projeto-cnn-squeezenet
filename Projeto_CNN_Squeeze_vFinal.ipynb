{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto_CNN_Squeeze_vFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1wzgfClBCqoV",
        "ApFgSRgHDIPU",
        "ruCjC2bMDPr-",
        "1Km_PHpFECl4",
        "XoMX8WVPD-ll",
        "NkL4_aCdD570",
        "l_8aLwEiDtqZ",
        "CxY-SCSQDxOw",
        "GvVQ4eNqDWID",
        "owghqPlyEF9E",
        "FQxas_T8EpAT",
        "HUwsp1iWEbBU"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renanalencar/projeto-cnn-squeezenet/blob/main/Projeto_CNN_Squeeze_vFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TF_Ahcf1Wpk"
      },
      "source": [
        "# Projeto de Redes Neurais "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OTE95hcbO3U"
      },
      "source": [
        "## Referências: \n",
        "\n",
        "1. [Estudo sobre Câncer de Cólon utilizando a mesma base com modelod e CNN](https://www.kaggle.com/aayushrajput/lung-colon-cancer)\n",
        "2. [Modelo de SqueezeNet para reconhecimento de comida](https://www.kaggle.com/kmader/food-squeezenet) \n",
        "3. [SqueezeNet no Keras](https://codelabs.developers.google.com/codelabs/keras-flowers-squeezenet#6)\n",
        "4. [Entendendo Redes Convolucionais (CNNs) ](https://medium.com/neuronio-br/entendendo-redes-convolucionais-cnns-d10359f21184#:~:text=H%C3%A1%20muitas%20fun%C3%A7%C3%B5es%2C%20como%20sigmoid,quando%20comparada%20a%20outras%20fun%C3%A7%C3%B5es)\n",
        "5. [Uma introdução as redes neurais convolucionais utilizando o Keras](https://medium.com/data-hackers/uma-introdu%C3%A7%C3%A3o-as-redes-neurais-convolucionais-utilizando-o-keras-41ee8dcc033e)\n",
        "6. [Tutorial prático do Keras](https://cv-tricks.com/tensorflow-tutorial/keras/)\n",
        "7. [Métricas de avaliação de modelo](https://gabrielschade.github.io/2019/03/12/ml-classificacao-metricas.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsSxQJGtbqY0"
      },
      "source": [
        "## Erro na biblioteca keras_applications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iGEAqxx2l_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7fd27e-6564-41cc-d369-3e7bfcde2d52"
      },
      "source": [
        "!pip install keras_applications"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mNIpyhd1b2b"
      },
      "source": [
        "## Importanto as bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-06T02:26:25.508587Z",
          "iopub.status.busy": "2021-01-06T02:26:25.507936Z",
          "iopub.status.idle": "2021-01-06T02:26:32.576008Z",
          "shell.execute_reply": "2021-01-06T02:26:32.576483Z"
        },
        "id": "iAve6DCL4JH4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe0dd9a-53dd-4e17-cd38-6b586324421f"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "from keras import backend as K\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.models import Model, model_from_json\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.layers import Input, Activation, concatenate\n",
        "from keras.layers import Flatten, Dropout\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D,Conv2D\n",
        "from keras.layers import AveragePooling2D, BatchNormalization\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import get_file\n",
        "from keras.utils import layer_utils\n",
        "from sklearn.metrics import f1_score,recall_score, precision_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('error')\n",
        "\n",
        "# from visual_callbacks import AccLossPlotter\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83elpmo35iWc"
      },
      "source": [
        "## Pré-processamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F3v9sfRFmoc"
      },
      "source": [
        "O conjunto de dados contém 15.000 imagens coloridas em 3 classes, com 5.000 imagens em cada classe. O conjunto de dados é dividido em 12.000 imagens de treinamento e 3.000 imagens de teste (split de 0.2). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJnvXAzwCWvu"
      },
      "source": [
        "### Variáveis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCmmex5F3MEb"
      },
      "source": [
        "base_dir = '/content/drive/Shareddrives/REDES_NEURAIS_ENG74317/projeto_cnn_squeezenet'\n",
        "data_dir = base_dir + '/input/lung_image_sets_teste/' # Diretório das imagems \n",
        "width, height, nb_class = 768, 768, 3 # Dimensões da entrada\n",
        "batch_size = 64 # Tamanho do lote para treinamento\n",
        "shuffle = True # Sortear as amostras \n",
        "seed = 42 # Número de sementes \n",
        "nb_epoch = 3 # Número de épocas \n",
        "loss='categorical_crossentropy' # Algoritmo de optmização das Redes Convolucionais\n",
        "optimizer_cnn='adam' # Algoritmo de optmização das Redes Convolucionais\n",
        "optimizer_sn = 'sgd' # Algoritmo de optmização da SqueezeNet\n",
        "metrics='accuracy' # Métrica utilizada \n",
        "target_size = (width, height)\n",
        "input_shape =  (width, height, nb_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CybAIz5xCh3p"
      },
      "source": [
        "### Pré-processamento das imagens "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbb2Fq_K09zX"
      },
      "source": [
        "def PreProcess(data_dir,target_size,batch_size,shuffle,seed):\n",
        "    \n",
        "    datagen_cnn = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. /255, validation_split = 0.2)\n",
        "\n",
        "    train_cnn = datagen_cnn.flow_from_directory(\n",
        "                                          data_dir,                                 \n",
        "                                          class_mode = \"categorical\",\n",
        "                                          target_size = target_size,\n",
        "                                          color_mode=\"rgb\",\n",
        "                                          batch_size = batch_size, \n",
        "                                          shuffle = shuffle,\n",
        "                                          subset='training',\n",
        "                                          seed = seed)\n",
        "\n",
        "    validation_cnn = datagen_cnn.flow_from_directory(\n",
        "                                          data_dir,\n",
        "                                          class_mode = \"categorical\",\n",
        "                                          target_size = target_size,\n",
        "                                          color_mode=\"rgb\",\n",
        "                                          batch_size = batch_size, \n",
        "                                          shuffle = shuffle,\n",
        "                                          subset='validation',\n",
        "                                          seed = seed)\n",
        "\n",
        "    return train_cnn, validation_cnn "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSxtv_xt0kpB"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUACoLEQF3rz"
      },
      "source": [
        "A saída de cada camada Conv2D e MaxPooling2D é um tensor 3D de forma (altura, largura, canais). As dimensões de altura e largura tendem a diminuir à medida que você se aprofunda na rede. O número de canais de saída para cada camada Conv2D é controlado pelo primeiro argumento (por exemplo, 32 ou 64). Normalmente, à medida que a largura e a altura diminuem, você pode (computacionalmente) adicionar mais canais de saída em cada camada Conv2D."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wzgfClBCqoV"
      },
      "source": [
        "### Modelo de CNN "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ruv4xxGP6L"
      },
      "source": [
        "As linhas de código abaixo definir a base convolucional utilizando um padrão comum: uma pilha de Conv2D e MaxPooling2D camadas.\n",
        "\n",
        "Como entrada, um CNN assume tensores de forma (image_height, image_width, color_channels), ignorando o tamanho do lote. O color_channels se refere a (R, G, B). A CNN foi configuradapara processar entradas de forma (768, 768, 3), que é o formato de imagens lung_image_sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Owmt1_ci-m0"
      },
      "source": [
        "def Model_CNN():\n",
        "  model = models.Sequential()\n",
        "\n",
        "  # BatchNormalization()(inp) testar o BatchNormalization\n",
        "  # Block 1\n",
        "  model.add(layers.BatchNormalization(input_shape=(768, 768, 3)))\n",
        "  # model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv1', input_shape=(768, 768, 3))) # Original\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv1'))\n",
        "  model.add(layers.Conv2D(32, (1, 1), activation='relu',name='block1_conv2'))\n",
        "  model.add(layers.MaxPooling2D((2, 2),strides=(2, 2), name='block1_pool'))\n",
        "\n",
        "  # Block 2\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', name='block2_conv1'))\n",
        "  model.add(layers.Conv2D(64, (1, 1), activation='relu',name='block2_conv2'))\n",
        "  model.add(layers.MaxPooling2D((2, 2),strides=(2, 2), name='block2_pool'))\n",
        "\n",
        "  # Block 3\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu',name='block3_conv1'))\n",
        "  model.add(layers.Conv2D(128, (1, 1), activation='relu',name='block3_conv2'))\n",
        "  model.add(layers.MaxPooling2D((2, 2),strides=(2, 2), name='block3_pool'))\n",
        "\n",
        "  # Block 4\n",
        "  model.add(layers.Conv2D(256, (3, 3), activation='relu',name='block4_conv1'))\n",
        "  model.add(layers.Conv2D(256, (1, 1), activation='relu',name='block4_conv2'))\n",
        "  model.add(layers.MaxPooling2D((2, 2),strides=(2, 2), name='block4_pool'))\n",
        "\n",
        "  # Block 5\n",
        "  model.add(layers.Conv2D(512, (3, 3), activation='relu',name='block5_conv1'))\n",
        "  model.add(layers.Conv2D(512, (1, 1), activation='relu',name='block5_conv2'))\n",
        "  model.add(layers.MaxPooling2D((2, 2),strides=(2, 2), name='block5_pool'))\n",
        "\n",
        "  # Flatten\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0quSU-YgGhgn"
      },
      "source": [
        "As (768, 768, 64) saídas serão achatadas em vetores de forma (387) antes de passar por duas camadas densas.\n",
        "\n",
        "Para completar o modelo, o último tensor de saída da base convolucional (de formato (4, 4, 64)) em uma ou mais camadas Densas para realizar a classificação. Camadas densas recebem vetores como entrada (que são 1D), enquanto a saída atual é um tensor 3D. Primeiro, você nivelará (ou desenrolará) a saída 3D em 1D e, em seguida, adicionará uma ou mais camadas Densas na parte superior. O conjunto tem 3 classes de saída, então você usa uma camada Densa final com 3 saídas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZKGXxHhCv0s"
      },
      "source": [
        "### Função para compilar o modelo da CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pulpavwaDk0m"
      },
      "source": [
        "def Compile_Model_CNN(loss, optimizer_cnn, metrics):\n",
        "  model_cnn = Model_CNN()\n",
        "  model_cnn.compile(loss=loss, optimizer=optimizer_cnn, metrics=[metrics])\n",
        "  model_cnn.summary()\n",
        "  return model_cnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr7E0_4DC20D"
      },
      "source": [
        "### Função de treinamento da CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAJ7-eRj2bHg"
      },
      "source": [
        "def Train_Model_CNN(model_cnn, train_cnn, nb_epoch, validation_cnn):\n",
        "    history_cnn = model_cnn.fit(train_cnn, epochs = nb_epoch,  validation_data=validation_cnn)\n",
        "\n",
        "    # salvar modelo para posterior avaliação      \n",
        "    model_json = model_cnn.to_json()\n",
        "    model_name = \"Modelo_CNN\"\n",
        "    with open(base_dir + '/models/'+ model_name +\".json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    model_cnn.save_weights(base_dir + '/weights/'+ model_name +'.h5')\n",
        "    \n",
        "    return history_cnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj0ighk2C-D9"
      },
      "source": [
        "### Função para execução da CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5x3cr4BY7oW"
      },
      "source": [
        "def Execute_Model_CNN():\n",
        "    train_cnn, validation_cnn = PreProcess(data_dir,target_size,batch_size,shuffle,seed)\n",
        "    model_cnn = Compile_Model_CNN(loss, optimizer_cnn, metrics)\n",
        "    \n",
        "    history_cnn = Train_Model_CNN(model_cnn, train_cnn, nb_epoch, validation_cnn)\n",
        "    \n",
        "    # Plotar a curva de aprendizagem\n",
        "    history_dict = history_cnn.history\n",
        "    loss_values = history_dict['loss']\n",
        "    val_loss_values = history_dict['val_loss']\n",
        "    accuracy = history_dict['accuracy']\n",
        "    val_accuracy = history_dict['val_accuracy']\n",
        "    \n",
        "    epochs = range(1, len(loss_values) + 1)\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "    # Plotar a Perdas vs Épocas\n",
        "    ax.plot(epochs, loss_values, 'bo', label='Perda de treinamento')\n",
        "    ax.plot(epochs, val_loss_values, 'b', label='Perda de validação')\n",
        "    ax.set_title('Perdas de Treinamento & Validação', fontsize=16)\n",
        "    ax.set_xlabel('Épocas', fontsize=16)\n",
        "    ax.set_ylabel('Perdas', fontsize=16)\n",
        "    ax.legend()\n",
        "\n",
        "    ax.figure.savefig(base_dir + '/graphs/' + 'Curva_de_aprendizagem_CNN.png')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApFgSRgHDIPU"
      },
      "source": [
        "### Função para avaliação  da CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTtM4Q_J3F4C"
      },
      "source": [
        "def Evaluate_Model_CNN():\n",
        "\n",
        "    train_cnn, validation_cnn = PreProcess(data_dir,target_size,batch_size,shuffle,seed)\n",
        "\n",
        "    # Recuperando o modelo Treinado da CNN\n",
        "    with open(base_dir + '/models/' + 'Modelo_CNN.json','r') as modelo:\n",
        "      json = modelo.read()\n",
        "    model_cnn = model_from_json(json)\n",
        "\n",
        "    # Recuperando os pesos do treinamento da CNN\n",
        "    model_cnn.load_weights(base_dir + '/weights/' + 'Modelo_CNN.h5') \n",
        "\n",
        "    # predicted_cnn = model_cnn.predict(validation_cnn)\n",
        "\n",
        "    # Y_pred = model_cnn.predict_generator(validation_cnn, steps=4500 // batchsize+1)\n",
        "    Y_pred = model_cnn.predict(validation_cnn)\n",
        "    y_pred = np.argmax(Y_pred, axis=1)\n",
        "    \n",
        "    print('\\nMatriz de Confusão')\n",
        "    print(confusion_matrix(validation_cnn.classes, y_pred),'\\n')\n",
        "\n",
        "    print(\" ---- F1 Score ----\")\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'weighted'),'\\n')\n",
        "\n",
        "    print(\" ---- Recall ----\")\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'weighted'),'\\n')\n",
        "    \n",
        "    print(\" ---- Precision ----\")\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'micro', zero_division=1))\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'macro', zero_division=1))\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'weighted', zero_division=1),'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BuGcrBcDLz7"
      },
      "source": [
        "### Chamada para execução da CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "pbF9sxmW3nIN",
        "outputId": "fc506daf-e614-4ba0-dce7-dd21377d3c06"
      },
      "source": [
        "Execute_Model_CNN()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ede9ae5726ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mExecute_Model_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-625c6a8b80be>\u001b[0m in \u001b[0;36mExecute_Model_CNN\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mExecute_Model_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompile_Model_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhistory_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_Model_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-e205a5360daa>\u001b[0m in \u001b[0;36mPreProcess\u001b[0;34m(data_dir, target_size, batch_size, shuffle, seed)\u001b[0m\n\u001b[1;32m     11\u001b[0m                                           \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                           \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                           seed = seed)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     validation_cnn = datagen_cnn.flow_from_directory(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Shareddrives/REDES_NEURAIS_ENG74317/projeto_cnn_squeezenet/input/lung_image_sets_teste/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruCjC2bMDPr-"
      },
      "source": [
        "### Chamada para avaliação da CNN\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zYrxTys3pPe",
        "outputId": "b158ce68-1c53-484f-e733-2060d2dda73f"
      },
      "source": [
        "Evaluate_Model_CNN()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12000 images belonging to 3 classes.\n",
            "Found 3000 images belonging to 3 classes.\n",
            "\n",
            "Matriz de Confusão\n",
            "[[   0    0 1000]\n",
            " [   0    0 1000]\n",
            " [   0    0 1000]] \n",
            "\n",
            " ---- F1 Score ----\n",
            "0.3333333333333333\n",
            "0.16666666666666666\n",
            "0.16666666666666666 \n",
            "\n",
            " ---- Recall ----\n",
            "0.3333333333333333\n",
            "0.3333333333333333\n",
            "0.3333333333333333 \n",
            "\n",
            " ---- Precision ----\n",
            "0.3333333333333333\n",
            "0.7777777777777778\n",
            "0.7777777777777778 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR-_ob8w0szO"
      },
      "source": [
        "# VGG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Km_PHpFECl4"
      },
      "source": [
        "### Modelo VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBVnHogyt6y9"
      },
      "source": [
        "def Model_VGG():\n",
        "  model = VGG16(include_top=False, input_shape=(768, 768, 3))\n",
        "\n",
        "  for layer in model.layers:\n",
        "   layer.trainable = False\n",
        "  \n",
        "  flat1 = Flatten()(model.layers[-1].output)\n",
        "  class1 = Dense(1024, activation='relu')(flat1)\n",
        "  class2 = Dense(512, activation='relu')(class1)\n",
        "  class3 = Dense(256, activation='relu')(class2)\n",
        "  class4 = Dense(128, activation='relu')(class3)\n",
        "  output = Dense(3, activation='softmax')(class4)\n",
        "\n",
        "  model = Model(inputs=model.inputs, outputs=output)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoMX8WVPD-ll"
      },
      "source": [
        "### Função para compilar o modelo da VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KdWBQjDlur9"
      },
      "source": [
        "def Compile_Model_VGG(loss, optimizer_cnn, metrics):\n",
        "  \n",
        "  model_vgg = Model_VGG()\n",
        "  model_vgg.compile(loss=loss, optimizer=optimizer_cnn, metrics=[metrics])\n",
        "  model_vgg.summary()\n",
        "\n",
        "  return model_vgg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkL4_aCdD570"
      },
      "source": [
        "### Função de treinamento da VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I67NDqig2fYw"
      },
      "source": [
        "def Train_Model_VGG(model_vgg, train_cnn, nb_epoch, validation_cnn):\n",
        "     \n",
        "     history_vgg = model_vgg.fit(train_cnn, epochs = nb_epoch,  validation_data=validation_cnn)\n",
        "\n",
        "     # salvar modelo para posterior avaliação      \n",
        "     model_json = model_vgg.to_json()\n",
        "     model_name = \"Modelo_VGG\"\n",
        "     with open(base_dir + '/models/'+model_name+\".json\", \"w\") as json_file:\n",
        "      json_file.write(model_json)\n",
        "     model_vgg.save_weights(base_dir + '/weights/'+model_name+'.h5')\n",
        "\n",
        "     return history_vgg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_8aLwEiDtqZ"
      },
      "source": [
        "### Função para execução da VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAp8s5ZQ2yQB"
      },
      "source": [
        "def Execute_Model_VGG():\n",
        "  \n",
        "    train_cnn, validation_cnn = PreProcess(data_dir,target_size,batch_size,shuffle,seed)\n",
        "    model_vgg = Compile_Model_VGG(loss, optimizer_cnn, metrics)\n",
        "    history_vgg = Train_Model_VGG(model_vgg, train_cnn, nb_epoch, validation_cnn)\n",
        "\n",
        "    # Plotar a curva de aprendizagem\n",
        "    history_dict = history_vgg.history\n",
        "    loss_values = history_dict['loss']\n",
        "    val_loss_values = history_dict['val_loss']\n",
        "    accuracy = history_dict['accuracy']\n",
        "    val_accuracy = history_dict['val_accuracy']\n",
        "    \n",
        "    epochs = range(1, len(loss_values) + 1)\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "    # Plotar a Perdas vs Épocas\n",
        "    ax.plot(epochs, loss_values, 'bo', label='Perda de treinamento')\n",
        "    ax.plot(epochs, val_loss_values, 'b', label='Perda de validação')\n",
        "    ax.set_title('Perdas de Treinamento & Validação', fontsize=16)\n",
        "    ax.set_xlabel('Épocas', fontsize=16)\n",
        "    ax.set_ylabel('Perdas', fontsize=16)\n",
        "    ax.legend()\n",
        "\n",
        "    ax.figure.savefig(base_dir + '/graphs/' + 'Curva_de_aprendizagem_VGG.png')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxY-SCSQDxOw"
      },
      "source": [
        "### Função para avaliação  da VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Md9FUi21t0"
      },
      "source": [
        "def Evaluate_Model_VGG():\n",
        "\n",
        "    train_cnn, validation_cnn = PreProcess(data_dir,target_size,batch_size,shuffle,seed)\n",
        "\n",
        "    # Recuperando o modelo Treinado da CNN\n",
        "    with open(base_dir + '/models/' + 'Modelo_VGG.json','r') as modelo:\n",
        "      json = modelo.read()\n",
        "    model_vgg = model_from_json(json)\n",
        "\n",
        "    # Recuperando os pesos do treinamento da CNN\n",
        "    model_vgg.load_weights(base_dir + '/weights/' + 'Modelo_VGG.h5') \n",
        "\n",
        "    Y_pred = model_vgg.predict(validation_cnn)\n",
        "    y_pred = np.argmax(Y_pred, axis=1)\n",
        "    \n",
        "    print('\\nMatriz de Confusão')\n",
        "    print(confusion_matrix(validation_cnn.classes, y_pred),'\\n')\n",
        "\n",
        "    print(\" ---- F1 Score ----\")\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'weighted'),'\\n')\n",
        "\n",
        "    print(\" ---- Recall ----\")\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'weighted'),'\\n')\n",
        "    \n",
        "    print(\" ---- Precision ----\")\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'weighted', zero_division=1),'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-AlwkIODgbb"
      },
      "source": [
        "### Chamada para execução da VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpfw8xnX3h3x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "694301f8-1f31-410c-f68a-03630e7bc59a"
      },
      "source": [
        "Execute_Model_VGG()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12000 images belonging to 3 classes.\n",
            "Found 3000 images belonging to 3 classes.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 768, 768, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 768, 768, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 768, 768, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 384, 384, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 384, 384, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 384, 384, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 192, 192, 128)     0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 192, 192, 256)     295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 192, 192, 256)     590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 192, 192, 256)     590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 96, 96, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 96, 96, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 96, 96, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 96, 96, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 48, 48, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 48, 48, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 48, 48, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 48, 48, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 24, 24, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 294912)            0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1024)              301990912 \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 317,395,011\n",
            "Trainable params: 302,680,323\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "3000/3000 [==============================] - 525s 173ms/step - loss: 10.6402 - accuracy: 0.8587 - val_loss: 0.1114 - val_accuracy: 0.9623\n",
            "Epoch 2/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.3512 - accuracy: 0.9541 - val_loss: 0.3030 - val_accuracy: 0.9393\n",
            "Epoch 3/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.2903 - accuracy: 0.9813 - val_loss: 0.0978 - val_accuracy: 0.9753\n",
            "Epoch 4/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0436 - accuracy: 0.9935 - val_loss: 0.2485 - val_accuracy: 0.9567\n",
            "Epoch 5/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.1724 - accuracy: 0.9872 - val_loss: 0.2456 - val_accuracy: 0.9720\n",
            "Epoch 6/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0514 - accuracy: 0.9929 - val_loss: 0.2165 - val_accuracy: 0.9797\n",
            "Epoch 7/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.3631 - val_accuracy: 0.9517\n",
            "Epoch 8/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.1088 - accuracy: 0.9877 - val_loss: 0.6365 - val_accuracy: 0.9627\n",
            "Epoch 9/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0569 - accuracy: 0.9926 - val_loss: 0.2227 - val_accuracy: 0.9740\n",
            "Epoch 10/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0545 - accuracy: 0.9956 - val_loss: 0.6591 - val_accuracy: 0.9740\n",
            "Epoch 11/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0389 - accuracy: 0.9936 - val_loss: 0.3748 - val_accuracy: 0.9783\n",
            "Epoch 12/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0191 - accuracy: 0.9965 - val_loss: 0.3224 - val_accuracy: 0.9747\n",
            "Epoch 13/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4382 - val_accuracy: 0.9783\n",
            "Epoch 14/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 4.2242 - val_accuracy: 0.9687\n",
            "Epoch 15/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0418 - accuracy: 0.9969 - val_loss: 1.6242 - val_accuracy: 0.9793\n",
            "Epoch 16/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0273 - accuracy: 0.9966 - val_loss: 0.2161 - val_accuracy: 0.9773\n",
            "Epoch 17/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0151 - accuracy: 0.9990 - val_loss: 0.6304 - val_accuracy: 0.9793\n",
            "Epoch 18/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0263 - accuracy: 0.9959 - val_loss: 0.3355 - val_accuracy: 0.9763\n",
            "Epoch 19/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.4344 - val_accuracy: 0.9760\n",
            "Epoch 20/50\n",
            "3000/3000 [==============================] - 517s 172ms/step - loss: 0.0316 - accuracy: 0.9960 - val_loss: 0.2555 - val_accuracy: 0.9763\n",
            "Epoch 21/50\n",
            "3000/3000 [==============================] - 517s 172ms/step - loss: 0.0143 - accuracy: 0.9986 - val_loss: 0.9074 - val_accuracy: 0.9763\n",
            "Epoch 22/50\n",
            "3000/3000 [==============================] - 517s 172ms/step - loss: 0.0527 - accuracy: 0.9913 - val_loss: 0.2173 - val_accuracy: 0.9773\n",
            "Epoch 23/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 0.6482 - val_accuracy: 0.9773\n",
            "Epoch 24/50\n",
            "3000/3000 [==============================] - 517s 172ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6448 - val_accuracy: 0.9780\n",
            "Epoch 25/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.6431 - val_accuracy: 0.9780\n",
            "Epoch 26/50\n",
            "3000/3000 [==============================] - 517s 172ms/step - loss: 9.5798e-04 - accuracy: 0.9999 - val_loss: 0.6432 - val_accuracy: 0.9780\n",
            "Epoch 27/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.6440 - val_accuracy: 0.9780\n",
            "Epoch 28/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 5.8764e-04 - accuracy: 1.0000 - val_loss: 0.6486 - val_accuracy: 0.9780\n",
            "Epoch 29/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 6.8937e-04 - accuracy: 0.9999 - val_loss: 0.6515 - val_accuracy: 0.9783\n",
            "Epoch 30/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.6645 - val_accuracy: 0.9777\n",
            "Epoch 31/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.6513 - val_accuracy: 0.9783\n",
            "Epoch 32/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0127 - accuracy: 0.9992 - val_loss: 0.3959 - val_accuracy: 0.9723\n",
            "Epoch 33/50\n",
            "3000/3000 [==============================] - 517s 172ms/step - loss: 0.0581 - accuracy: 0.9974 - val_loss: 0.4075 - val_accuracy: 0.9593\n",
            "Epoch 34/50\n",
            "3000/3000 [==============================] - 517s 172ms/step - loss: 0.0128 - accuracy: 0.9980 - val_loss: 0.3997 - val_accuracy: 0.9743\n",
            "Epoch 35/50\n",
            "3000/3000 [==============================] - 517s 172ms/step - loss: 0.0317 - accuracy: 0.9969 - val_loss: 2.3706 - val_accuracy: 0.9653\n",
            "Epoch 36/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0163 - accuracy: 0.9993 - val_loss: 1.3200 - val_accuracy: 0.9777\n",
            "Epoch 37/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 1.0958 - val_accuracy: 0.9790\n",
            "Epoch 38/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 3.4000e-04 - accuracy: 0.9999 - val_loss: 1.2414 - val_accuracy: 0.9780\n",
            "Epoch 39/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 1.4629e-07 - accuracy: 1.0000 - val_loss: 1.2982 - val_accuracy: 0.9780\n",
            "Epoch 40/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 1.7511e-09 - accuracy: 1.0000 - val_loss: 1.3054 - val_accuracy: 0.9780\n",
            "Epoch 41/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 6.0673e-10 - accuracy: 1.0000 - val_loss: 1.3147 - val_accuracy: 0.9780\n",
            "Epoch 42/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 7.7789e-10 - accuracy: 1.0000 - val_loss: 1.4103 - val_accuracy: 0.9783\n",
            "Epoch 43/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 1.3950e-10 - accuracy: 1.0000 - val_loss: 1.4183 - val_accuracy: 0.9780\n",
            "Epoch 44/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 2.8363e-11 - accuracy: 1.0000 - val_loss: 1.4434 - val_accuracy: 0.9777\n",
            "Epoch 45/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 1.3673e-11 - accuracy: 1.0000 - val_loss: 1.4716 - val_accuracy: 0.9777\n",
            "Epoch 46/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 2.1488e-12 - accuracy: 1.0000 - val_loss: 1.5029 - val_accuracy: 0.9770\n",
            "Epoch 47/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5245 - val_accuracy: 0.9773\n",
            "Epoch 48/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5462 - val_accuracy: 0.9773\n",
            "Epoch 49/50\n",
            "3000/3000 [==============================] - 517s 172ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5773 - val_accuracy: 0.9773\n",
            "Epoch 50/50\n",
            "3000/3000 [==============================] - 516s 172ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6053 - val_accuracy: 0.9773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-9e0a3ed438f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mExecute_Model_VGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-9b6f8a8f1812>\u001b[0m in \u001b[0;36mExecute_Model_VGG\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_vgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompile_Model_VGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel_vgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_vgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_Model_VGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_vgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Plotar a curva de aprendizagem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable History object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvVQ4eNqDWID"
      },
      "source": [
        "### Chamada para avaliação da VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roJheMrn3sbX",
        "outputId": "308b91d9-f3ab-4156-df47-b79951442e0b"
      },
      "source": [
        "Evaluate_Model_VGG()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12000 images belonging to 3 classes.\n",
            "Found 3000 images belonging to 3 classes.\n",
            "\n",
            "Matriz de Confusão\n",
            "[[340 325 335]\n",
            " [325 334 341]\n",
            " [319 340 341]] \n",
            "\n",
            " ---- F1 Score ----\n",
            "0.3383333333333333\n",
            "0.3383449828746851\n",
            "0.33834498287468506 \n",
            "\n",
            " ---- Recall ----\n",
            "0.3383333333333333\n",
            "0.3383333333333334\n",
            "0.3383333333333333 \n",
            "\n",
            " ---- Precision ----\n",
            "0.3383333333333333\n",
            "0.3383875637634901\n",
            "0.3383875637634901 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTV_f7Ga0ukn"
      },
      "source": [
        "# SqueezeNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owghqPlyEF9E"
      },
      "source": [
        "### Modelo SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNGdcVZE0zfT"
      },
      "source": [
        "sq1x1 = \"squeeze1x1\"\n",
        "exp1x1 = \"expand1x1\"\n",
        "exp3x3 = \"expand3x3\"\n",
        "relu = \"relu_\"\n",
        "\n",
        "WEIGHTS_PATH = \"https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels.h5\"\n",
        "WEIGHTS_PATH_NO_TOP = \"https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "\n",
        "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
        "    s_id = 'fire' + str(fire_id) + '/'\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = 3\n",
        "    \n",
        "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
        "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
        "\n",
        "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
        "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
        "\n",
        "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
        "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
        "\n",
        "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
        "    return x\n",
        "\n",
        "\n",
        "def Model_SqzNet(include_top=True, weights='imagenet', \n",
        "               input_tensor=None, input_shape=None,\n",
        "               pooling=None,\n",
        "               use_bn_on_input = False,\n",
        "               classes=1000):\n",
        "    \"\"\"Instantiates the SqueezeNet architecture.\n",
        "    \"\"\"\n",
        "        \n",
        "    if weights not in {'imagenet', None}:\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `imagenet` '\n",
        "                         '(pre-training on ImageNet).')\n",
        "\n",
        "    if weights == 'imagenet' and classes != 1000:\n",
        "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=227,\n",
        "                                      min_size=48,\n",
        "                                      data_format=K.image_data_format(),\n",
        "                                      require_flatten=include_top)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        raw_img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if use_bn_on_input:\n",
        "        img_input = BatchNormalization()(raw_img_input)\n",
        "    else:\n",
        "        img_input = raw_img_input\n",
        "\n",
        "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
        "    x = Activation('relu', name='relu_conv1')(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
        "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
        "\n",
        "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
        "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
        "\n",
        "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
        "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
        "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
        "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
        "    \n",
        "    if include_top:\n",
        "    \n",
        "        x = Dropout(0.5, name='drop9')(x)\n",
        "\n",
        "        x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
        "        x = Activation('relu', name='relu_conv10')(x)\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Activation('softmax', name='loss')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling=='max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "        elif pooling==None:\n",
        "            pass\n",
        "        else:\n",
        "            raise ValueError(\"Unknown argument for 'pooling'=\" + pooling)\n",
        "\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "\n",
        "    model = Model(inputs, x, name='squeezenet')\n",
        "\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                                    WEIGHTS_PATH,\n",
        "                                    cache_subdir='models')\n",
        "        else:\n",
        "            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                                    WEIGHTS_PATH_NO_TOP,\n",
        "                                    cache_subdir='models')\n",
        "            \n",
        "        model.load_weights(weights_path)\n",
        "        if K.backend() == 'theano':\n",
        "            layer_utils.convert_all_kernels_in_model(model)\n",
        "\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "\n",
        "            if K.backend() == 'tensorflow':\n",
        "                print('You are using the TensorFlow backend, yet you '\n",
        "                              'are using the Theano '\n",
        "                              'image data format convention '\n",
        "                              '(`image_data_format=\"channels_first\"`). '\n",
        "                              'For best performance, set '\n",
        "                              '`image_data_format=\"channels_last\"` in '\n",
        "                              'your Keras config '\n",
        "                              'at ~/.keras/keras.json.')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQxas_T8EpAT"
      },
      "source": [
        "### Função para compilar o modelo da SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P445-sYxlwMu"
      },
      "source": [
        "def Compile_Model_SqzNet(input_shape, nb_class, loss, optimizer_sn, metrics):\n",
        " \n",
        "  model_sn = Model_SqzNet(input_shape=input_shape,  weights=None, classes = nb_class)\n",
        "  sgd = SGD(lr=0.001, decay=0.0002, momentum=0.9, nesterov=True)\n",
        "  model_sn.compile(loss=loss, optimizer=optimizer_sn, metrics=[metrics])\n",
        "  model_sn.summary()\n",
        "\n",
        "  return model_sn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6co5yNMElFk"
      },
      "source": [
        "### Função para treinamento  da SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH-cEMiO2_wQ"
      },
      "source": [
        "def Train_Model_SqzNet(model_sn, train_cnn, nb_epoch, validation_cnn):\n",
        "    \n",
        "    history_sn = model_sn.fit(train_cnn, epochs = nb_epoch,  validation_data=validation_cnn)\n",
        "\n",
        "    # salvar modelo para posterior avaliação      \n",
        "    model_json = model_sn.to_json()\n",
        "    model_name = \"Modelo_SqzNet\"\n",
        "    with open(base_dir + '/models/' + model_name + \".json\", \"w\") as json_file:\n",
        "      json_file.write(model_json)\n",
        "    model_sn.save_weights(base_dir + '/weights/' + model_name + '.h5')\n",
        "\n",
        "    return history_sn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzr9rgQbEcNq"
      },
      "source": [
        "### Função para execuação  da SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAOX9uo3mFBm"
      },
      "source": [
        "def Execute_Model_SqzNet():\n",
        "    \n",
        "    train_cnn, validation_cnn = PreProcess(data_dir,target_size,batch_size,shuffle,seed)\n",
        "    model_sn = Compile_Model_SqzNet(input_shape, nb_class, loss, optimizer_sn, metrics)\n",
        "    history_sn = Train_Model_SqzNet(model_sn, train_cnn, nb_epoch, validation_cnn)\n",
        "\n",
        "    # Plotar a curva de aprendizagem\n",
        "    history_dict = history_sn.history\n",
        "    loss_values = history_dict['loss']\n",
        "    val_loss_values = history_dict['val_loss']\n",
        "    accuracy = history_dict['accuracy']\n",
        "    val_accuracy = history_dict['val_accuracy']\n",
        "    \n",
        "    epochs = range(1, len(loss_values) + 1)\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "    # Plotar a Perdas vs Épocas\n",
        "    ax.plot(epochs, loss_values, 'bo', label='Perda de treinamento')\n",
        "    ax.plot(epochs, val_loss_values, 'b', label='Perda de validação')\n",
        "    ax.set_title('Perdas de Treinamento & Validação', fontsize=16)\n",
        "    ax.set_xlabel('Épocas', fontsize=16)\n",
        "    ax.set_ylabel('Perdas', fontsize=16)\n",
        "    ax.legend()\n",
        "\n",
        "    ax.figure.savefig(base_dir + '/graphs/' + 'Curva_de_aprendizagem_SqzNet.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUwsp1iWEbBU"
      },
      "source": [
        "### Função para avaliação  da SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5wa7dZ229Za"
      },
      "source": [
        "def Evaluate_Model_SqzNet():\n",
        "    \n",
        "    train_cnn, validation_cnn = PreProcess(data_dir,target_size,batch_size,shuffle,seed)\n",
        "\n",
        "    # Recuperando o modelo Treinado da CNN\n",
        "    with open(base_dir + '/models/' + 'Modelo_SqzNet.json','r') as modelo:\n",
        "      json = modelo.read()\n",
        "    model_vgg = model_from_json(json)\n",
        "\n",
        "    # Recuperando os pesos do treinamento da CNN\n",
        "    model_vgg.load_weights(base_dir + '/weights/' + 'Modelo_SqzNet.h5') \n",
        "\n",
        "    Y_pred = model_vgg.predict(validation_cnn)\n",
        "    y_pred = np.argmax(Y_pred, axis=1)\n",
        "    \n",
        "    print('\\nMatriz de Confusão')\n",
        "    print(confusion_matrix(validation_cnn.classes, y_pred),'\\n')\n",
        "\n",
        "    print(\" ---- F1 Score ----\")\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'weighted'),'\\n')\n",
        "\n",
        "    print(\" ---- Recall ----\")\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'weighted'),'\\n')\n",
        "    \n",
        "    print(\" ---- Precision ----\")\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'micro', zero_division=1))\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'macro', zero_division=1))\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'weighted', zero_division=1),'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n67p6KcnETjh"
      },
      "source": [
        "### Chamada para execução da SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDJ6IHafy6d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac2299b-e5a7-4804-be51-af9506cdbd5a"
      },
      "source": [
        "Execute_Model_SqzNet()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12000 images belonging to 3 classes.\n",
            "Found 3000 images belonging to 3 classes.\n",
            "Model: \"squeezenet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 768, 768, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 383, 383, 64) 1792        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "relu_conv1 (Activation)         (None, 383, 383, 64) 0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 191, 191, 64) 0           relu_conv1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "fire2/squeeze1x1 (Conv2D)       (None, 191, 191, 16) 1040        pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "fire2/relu_squeeze1x1 (Activati (None, 191, 191, 16) 0           fire2/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire2/expand1x1 (Conv2D)        (None, 191, 191, 64) 1088        fire2/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire2/expand3x3 (Conv2D)        (None, 191, 191, 64) 9280        fire2/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire2/relu_expand1x1 (Activatio (None, 191, 191, 64) 0           fire2/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire2/relu_expand3x3 (Activatio (None, 191, 191, 64) 0           fire2/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire2/concat (Concatenate)      (None, 191, 191, 128 0           fire2/relu_expand1x1[0][0]       \n",
            "                                                                 fire2/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire3/squeeze1x1 (Conv2D)       (None, 191, 191, 16) 2064        fire2/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire3/relu_squeeze1x1 (Activati (None, 191, 191, 16) 0           fire3/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire3/expand1x1 (Conv2D)        (None, 191, 191, 64) 1088        fire3/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire3/expand3x3 (Conv2D)        (None, 191, 191, 64) 9280        fire3/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire3/relu_expand1x1 (Activatio (None, 191, 191, 64) 0           fire3/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire3/relu_expand3x3 (Activatio (None, 191, 191, 64) 0           fire3/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire3/concat (Concatenate)      (None, 191, 191, 128 0           fire3/relu_expand1x1[0][0]       \n",
            "                                                                 fire3/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3 (MaxPooling2D)            (None, 95, 95, 128)  0           fire3/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire4/squeeze1x1 (Conv2D)       (None, 95, 95, 32)   4128        pool3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "fire4/relu_squeeze1x1 (Activati (None, 95, 95, 32)   0           fire4/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire4/expand1x1 (Conv2D)        (None, 95, 95, 128)  4224        fire4/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire4/expand3x3 (Conv2D)        (None, 95, 95, 128)  36992       fire4/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire4/relu_expand1x1 (Activatio (None, 95, 95, 128)  0           fire4/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire4/relu_expand3x3 (Activatio (None, 95, 95, 128)  0           fire4/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire4/concat (Concatenate)      (None, 95, 95, 256)  0           fire4/relu_expand1x1[0][0]       \n",
            "                                                                 fire4/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire5/squeeze1x1 (Conv2D)       (None, 95, 95, 32)   8224        fire4/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire5/relu_squeeze1x1 (Activati (None, 95, 95, 32)   0           fire5/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire5/expand1x1 (Conv2D)        (None, 95, 95, 128)  4224        fire5/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire5/expand3x3 (Conv2D)        (None, 95, 95, 128)  36992       fire5/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire5/relu_expand1x1 (Activatio (None, 95, 95, 128)  0           fire5/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire5/relu_expand3x3 (Activatio (None, 95, 95, 128)  0           fire5/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire5/concat (Concatenate)      (None, 95, 95, 256)  0           fire5/relu_expand1x1[0][0]       \n",
            "                                                                 fire5/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool5 (MaxPooling2D)            (None, 47, 47, 256)  0           fire5/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire6/squeeze1x1 (Conv2D)       (None, 47, 47, 48)   12336       pool5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "fire6/relu_squeeze1x1 (Activati (None, 47, 47, 48)   0           fire6/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire6/expand1x1 (Conv2D)        (None, 47, 47, 192)  9408        fire6/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire6/expand3x3 (Conv2D)        (None, 47, 47, 192)  83136       fire6/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire6/relu_expand1x1 (Activatio (None, 47, 47, 192)  0           fire6/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire6/relu_expand3x3 (Activatio (None, 47, 47, 192)  0           fire6/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire6/concat (Concatenate)      (None, 47, 47, 384)  0           fire6/relu_expand1x1[0][0]       \n",
            "                                                                 fire6/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire7/squeeze1x1 (Conv2D)       (None, 47, 47, 48)   18480       fire6/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire7/relu_squeeze1x1 (Activati (None, 47, 47, 48)   0           fire7/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire7/expand1x1 (Conv2D)        (None, 47, 47, 192)  9408        fire7/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire7/expand3x3 (Conv2D)        (None, 47, 47, 192)  83136       fire7/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire7/relu_expand1x1 (Activatio (None, 47, 47, 192)  0           fire7/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire7/relu_expand3x3 (Activatio (None, 47, 47, 192)  0           fire7/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire7/concat (Concatenate)      (None, 47, 47, 384)  0           fire7/relu_expand1x1[0][0]       \n",
            "                                                                 fire7/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire8/squeeze1x1 (Conv2D)       (None, 47, 47, 64)   24640       fire7/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire8/relu_squeeze1x1 (Activati (None, 47, 47, 64)   0           fire8/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire8/expand1x1 (Conv2D)        (None, 47, 47, 256)  16640       fire8/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire8/expand3x3 (Conv2D)        (None, 47, 47, 256)  147712      fire8/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire8/relu_expand1x1 (Activatio (None, 47, 47, 256)  0           fire8/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire8/relu_expand3x3 (Activatio (None, 47, 47, 256)  0           fire8/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire8/concat (Concatenate)      (None, 47, 47, 512)  0           fire8/relu_expand1x1[0][0]       \n",
            "                                                                 fire8/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire9/squeeze1x1 (Conv2D)       (None, 47, 47, 64)   32832       fire8/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire9/relu_squeeze1x1 (Activati (None, 47, 47, 64)   0           fire9/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire9/expand1x1 (Conv2D)        (None, 47, 47, 256)  16640       fire9/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire9/expand3x3 (Conv2D)        (None, 47, 47, 256)  147712      fire9/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire9/relu_expand1x1 (Activatio (None, 47, 47, 256)  0           fire9/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire9/relu_expand3x3 (Activatio (None, 47, 47, 256)  0           fire9/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire9/concat (Concatenate)      (None, 47, 47, 512)  0           fire9/relu_expand1x1[0][0]       \n",
            "                                                                 fire9/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "drop9 (Dropout)                 (None, 47, 47, 512)  0           fire9/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv10 (Conv2D)                 (None, 47, 47, 3)    1539        drop9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu_conv10 (Activation)        (None, 47, 47, 3)    0           conv10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 3)            0           relu_conv10[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "loss (Activation)               (None, 3)            0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 724,035\n",
            "Trainable params: 724,035\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "3000/3000 [==============================] - 242s 80ms/step - loss: 0.9621 - accuracy: 0.4784 - val_loss: 0.6167 - val_accuracy: 0.6923\n",
            "Epoch 2/50\n",
            "3000/3000 [==============================] - 240s 80ms/step - loss: 0.4974 - accuracy: 0.7953 - val_loss: 0.3222 - val_accuracy: 0.8860\n",
            "Epoch 3/50\n",
            "3000/3000 [==============================] - 241s 80ms/step - loss: 0.3239 - accuracy: 0.8771 - val_loss: 0.5511 - val_accuracy: 0.6990\n",
            "Epoch 4/50\n",
            "3000/3000 [==============================] - 241s 80ms/step - loss: 0.4821 - accuracy: 0.7637 - val_loss: 0.2933 - val_accuracy: 0.8823\n",
            "Epoch 5/50\n",
            "3000/3000 [==============================] - 241s 80ms/step - loss: 0.2792 - accuracy: 0.8872 - val_loss: 0.2340 - val_accuracy: 0.9080\n",
            "Epoch 6/50\n",
            "3000/3000 [==============================] - 241s 80ms/step - loss: 0.2533 - accuracy: 0.9029 - val_loss: 0.2150 - val_accuracy: 0.9073\n",
            "Epoch 7/50\n",
            "3000/3000 [==============================] - 241s 80ms/step - loss: 0.2361 - accuracy: 0.9083 - val_loss: 0.1919 - val_accuracy: 0.9163\n",
            "Epoch 8/50\n",
            "3000/3000 [==============================] - 241s 80ms/step - loss: 0.2121 - accuracy: 0.9185 - val_loss: 0.1811 - val_accuracy: 0.9183\n",
            "Epoch 9/50\n",
            "3000/3000 [==============================] - 240s 80ms/step - loss: 0.2008 - accuracy: 0.9225 - val_loss: 0.1640 - val_accuracy: 0.9350\n",
            "Epoch 10/50\n",
            "3000/3000 [==============================] - 237s 79ms/step - loss: 0.1954 - accuracy: 0.9214 - val_loss: 0.1691 - val_accuracy: 0.9313\n",
            "Epoch 11/50\n",
            "3000/3000 [==============================] - 237s 79ms/step - loss: 0.1784 - accuracy: 0.9296 - val_loss: 0.2809 - val_accuracy: 0.8673\n",
            "Epoch 12/50\n",
            "3000/3000 [==============================] - 237s 79ms/step - loss: 0.1647 - accuracy: 0.9359 - val_loss: 0.1617 - val_accuracy: 0.9333\n",
            "Epoch 13/50\n",
            "3000/3000 [==============================] - 238s 79ms/step - loss: 0.1687 - accuracy: 0.9354 - val_loss: 0.1322 - val_accuracy: 0.9470\n",
            "Epoch 14/50\n",
            "3000/3000 [==============================] - 238s 79ms/step - loss: 0.1543 - accuracy: 0.9363 - val_loss: 0.3653 - val_accuracy: 0.8853\n",
            "Epoch 15/50\n",
            "3000/3000 [==============================] - 238s 79ms/step - loss: 0.1811 - accuracy: 0.9311 - val_loss: 0.1798 - val_accuracy: 0.9387\n",
            "Epoch 16/50\n",
            "3000/3000 [==============================] - 238s 79ms/step - loss: 0.2002 - accuracy: 0.9185 - val_loss: 0.2026 - val_accuracy: 0.9130\n",
            "Epoch 17/50\n",
            "3000/3000 [==============================] - 238s 79ms/step - loss: 0.1901 - accuracy: 0.9222 - val_loss: 0.1705 - val_accuracy: 0.9300\n",
            "Epoch 18/50\n",
            "3000/3000 [==============================] - 238s 79ms/step - loss: 0.1670 - accuracy: 0.9332 - val_loss: 0.1420 - val_accuracy: 0.9473\n",
            "Epoch 19/50\n",
            "3000/3000 [==============================] - 238s 79ms/step - loss: 0.1526 - accuracy: 0.9402 - val_loss: 0.1727 - val_accuracy: 0.9347\n",
            "Epoch 20/50\n",
            "3000/3000 [==============================] - 238s 79ms/step - loss: 0.1362 - accuracy: 0.9464 - val_loss: 0.1788 - val_accuracy: 0.9333\n",
            "Epoch 21/50\n",
            "3000/3000 [==============================] - 238s 79ms/step - loss: 0.1320 - accuracy: 0.9481 - val_loss: 0.1102 - val_accuracy: 0.9557\n",
            "Epoch 22/50\n",
            "3000/3000 [==============================] - 238s 79ms/step - loss: 0.1321 - accuracy: 0.9485 - val_loss: 0.1220 - val_accuracy: 0.9533\n",
            "Epoch 23/50\n",
            "3000/3000 [==============================] - 236s 79ms/step - loss: 0.1296 - accuracy: 0.9474 - val_loss: 0.1118 - val_accuracy: 0.9550\n",
            "Epoch 24/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.1226 - accuracy: 0.9493 - val_loss: 0.1109 - val_accuracy: 0.9570\n",
            "Epoch 25/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.1222 - accuracy: 0.9530 - val_loss: 0.1045 - val_accuracy: 0.9623\n",
            "Epoch 26/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.1152 - accuracy: 0.9521 - val_loss: 0.1065 - val_accuracy: 0.9567\n",
            "Epoch 27/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.1160 - accuracy: 0.9550 - val_loss: 0.1122 - val_accuracy: 0.9543\n",
            "Epoch 28/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.1311 - accuracy: 0.9439 - val_loss: 0.0922 - val_accuracy: 0.9653\n",
            "Epoch 29/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.1039 - accuracy: 0.9581 - val_loss: 0.1398 - val_accuracy: 0.9477\n",
            "Epoch 30/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.1008 - accuracy: 0.9617 - val_loss: 0.1025 - val_accuracy: 0.9617\n",
            "Epoch 31/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.1001 - accuracy: 0.9602 - val_loss: 0.1828 - val_accuracy: 0.9320\n",
            "Epoch 32/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.1010 - accuracy: 0.9625 - val_loss: 0.0891 - val_accuracy: 0.9677\n",
            "Epoch 33/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.1277 - accuracy: 0.9534 - val_loss: 0.1271 - val_accuracy: 0.9527\n",
            "Epoch 34/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.1010 - accuracy: 0.9613 - val_loss: 0.1333 - val_accuracy: 0.9527\n",
            "Epoch 35/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0978 - accuracy: 0.9612 - val_loss: 0.1095 - val_accuracy: 0.9573\n",
            "Epoch 36/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0954 - accuracy: 0.9633 - val_loss: 0.0853 - val_accuracy: 0.9650\n",
            "Epoch 37/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0921 - accuracy: 0.9640 - val_loss: 0.0967 - val_accuracy: 0.9640\n",
            "Epoch 38/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0883 - accuracy: 0.9647 - val_loss: 0.0850 - val_accuracy: 0.9650\n",
            "Epoch 39/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0776 - accuracy: 0.9713 - val_loss: 0.1366 - val_accuracy: 0.9453\n",
            "Epoch 40/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0783 - accuracy: 0.9690 - val_loss: 0.0816 - val_accuracy: 0.9667\n",
            "Epoch 41/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0673 - accuracy: 0.9750 - val_loss: 0.1093 - val_accuracy: 0.9643\n",
            "Epoch 42/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0742 - accuracy: 0.9738 - val_loss: 0.1839 - val_accuracy: 0.9313\n",
            "Epoch 43/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0818 - accuracy: 0.9707 - val_loss: 0.1505 - val_accuracy: 0.9480\n",
            "Epoch 44/50\n",
            "3000/3000 [==============================] - 233s 78ms/step - loss: 0.0698 - accuracy: 0.9733 - val_loss: 0.0740 - val_accuracy: 0.9717\n",
            "Epoch 45/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0782 - accuracy: 0.9696 - val_loss: 0.0988 - val_accuracy: 0.9613\n",
            "Epoch 46/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0715 - accuracy: 0.9738 - val_loss: 0.3431 - val_accuracy: 0.9233\n",
            "Epoch 47/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0697 - accuracy: 0.9730 - val_loss: 0.1401 - val_accuracy: 0.9553\n",
            "Epoch 48/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0717 - accuracy: 0.9713 - val_loss: 0.0969 - val_accuracy: 0.9573\n",
            "Epoch 49/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0651 - accuracy: 0.9729 - val_loss: 0.0620 - val_accuracy: 0.9760\n",
            "Epoch 50/50\n",
            "3000/3000 [==============================] - 232s 77ms/step - loss: 0.0620 - accuracy: 0.9770 - val_loss: 0.1005 - val_accuracy: 0.9620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_pKf6nfEM7l"
      },
      "source": [
        "### Chamada para avaliação da SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q88gD9E3yoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6586cc90-07f6-40a4-8e36-60940b537b56"
      },
      "source": [
        "Evaluate_Model_SqzNet()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12000 images belonging to 3 classes.\n",
            "Found 3000 images belonging to 3 classes.\n",
            "\n",
            "Matriz de Confusão\n",
            "[[366 325 309]\n",
            " [363 329 308]\n",
            " [345 338 317]] \n",
            "\n",
            " ---- F1 Score ----\n",
            "0.3373333333333333\n",
            "0.33702681846879784\n",
            "0.3370268184687978 \n",
            "\n",
            " ---- Recall ----\n",
            "0.3373333333333333\n",
            "0.3373333333333333\n",
            "0.3373333333333333 \n",
            "\n",
            " ---- Precision ----\n",
            "0.3373333333333333\n",
            "0.33727859232566804\n",
            "0.33727859232566804 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
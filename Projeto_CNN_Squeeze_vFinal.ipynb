{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Projeto_CNN_Squeeze_vFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qsSxQJGtbqY0",
        "-mNIpyhd1b2b",
        "cJnvXAzwCWvu",
        "CybAIz5xCh3p",
        "fSxtv_xt0kpB",
        "1wzgfClBCqoV",
        "fZKGXxHhCv0s",
        "lr7E0_4DC20D",
        "gj0ighk2C-D9",
        "ApFgSRgHDIPU",
        "6BuGcrBcDLz7",
        "ruCjC2bMDPr-",
        "iR-_ob8w0szO",
        "1Km_PHpFECl4",
        "XoMX8WVPD-ll",
        "NkL4_aCdD570",
        "l_8aLwEiDtqZ",
        "CxY-SCSQDxOw",
        "j-AlwkIODgbb",
        "GvVQ4eNqDWID",
        "jTV_f7Ga0ukn",
        "owghqPlyEF9E",
        "FQxas_T8EpAT",
        "O6co5yNMElFk",
        "Yzr9rgQbEcNq",
        "HUwsp1iWEbBU",
        "n67p6KcnETjh"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TF_Ahcf1Wpk"
      },
      "source": [
        "# Projeto de Redes Neurais "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OTE95hcbO3U"
      },
      "source": [
        "## Referências: \n",
        "\n",
        "1. [Estudo sobre Câncer de Cólon utilizando a mesma base com modelod e CNN](https://www.kaggle.com/aayushrajput/lung-colon-cancer)\n",
        "2. [Modelo de SqueezeNet para reconhecimento de comida](https://www.kaggle.com/kmader/food-squeezenet) \n",
        "3. [SqueezeNet no Keras](https://codelabs.developers.google.com/codelabs/keras-flowers-squeezenet#6)\n",
        "4. [Entendendo Redes Convolucionais (CNNs) ](https://medium.com/neuronio-br/entendendo-redes-convolucionais-cnns-d10359f21184#:~:text=H%C3%A1%20muitas%20fun%C3%A7%C3%B5es%2C%20como%20sigmoid,quando%20comparada%20a%20outras%20fun%C3%A7%C3%B5es)\n",
        "5. [Uma introdução as redes neurais convolucionais utilizando o Keras](https://medium.com/data-hackers/uma-introdu%C3%A7%C3%A3o-as-redes-neurais-convolucionais-utilizando-o-keras-41ee8dcc033e)\n",
        "6. [Tutorial prático do Keras](https://cv-tricks.com/tensorflow-tutorial/keras/)\n",
        "7. [Métricas de avaliação de modelo](https://gabrielschade.github.io/2019/03/12/ml-classificacao-metricas.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsSxQJGtbqY0"
      },
      "source": [
        "## Erro na biblioteca keras_applications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iGEAqxx2l_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84d487b-d6b8-49f6-9bbf-f6a17752248a"
      },
      "source": [
        "!pip install keras_applications"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mNIpyhd1b2b"
      },
      "source": [
        "## Importanto as bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-06T02:26:25.508587Z",
          "iopub.status.busy": "2021-01-06T02:26:25.507936Z",
          "iopub.status.idle": "2021-01-06T02:26:32.576008Z",
          "shell.execute_reply": "2021-01-06T02:26:32.576483Z"
        },
        "id": "iAve6DCL4JH4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e756f91-7ddf-4c0f-d00e-efdde5fabb6f"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "from keras import backend as K\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.models import Model, model_from_json\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.layers import Input, Activation, concatenate\n",
        "from keras.layers import Flatten, Dropout\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D,Conv2D\n",
        "from keras.layers import AveragePooling2D, BatchNormalization\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import get_file\n",
        "from keras.utils import layer_utils\n",
        "from sklearn.metrics import f1_score,recall_score, precision_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('error')\n",
        "\n",
        "# from visual_callbacks import AccLossPlotter\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <_io.FileIO name=84 mode='wb' closefd=True>\n",
            "ResourceWarning: unclosed file <_io.FileIO name=84 mode='wb' closefd=True>\n",
            "Exception ignored in: <_io.FileIO name=87 mode='rb' closefd=True>\n",
            "ResourceWarning: unclosed file <_io.FileIO name=87 mode='rb' closefd=True>\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83elpmo35iWc"
      },
      "source": [
        "## Pré-processamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F3v9sfRFmoc"
      },
      "source": [
        "O conjunto de dados contém 15.000 imagens coloridas em 3 classes, com 5.000 imagens em cada classe. O conjunto de dados é dividido em 12.000 imagens de treinamento e 3.000 imagens de teste. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJnvXAzwCWvu"
      },
      "source": [
        "### Variáveis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCmmex5F3MEb"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/lung_image_sets/' # Diretório das imagems \n",
        "width, height, nb_class = 768, 768, 3 # Dimensões da entrada\n",
        "batch_size = 4 # Tamanho do lote para treinamento\n",
        "shuffle = True # Sortear as amostras \n",
        "seed = 42 # Número de sementes \n",
        "nb_epoch = 1 # Número de épocas \n",
        "loss='categorical_crossentropy' # Algoritmo de optmização das Redes Convolucionais\n",
        "optimizer_cnn='adam' # Algoritmo de optmização das Redes Convolucionais\n",
        "optimizer_sn = 'sgd' # Algoritmo de optmização da SqueezeNet\n",
        "metrics='accuracy' # Métrica utilizada \n",
        "target_size = (width, height)\n",
        "input_shape =  (width, height, nb_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CybAIz5xCh3p"
      },
      "source": [
        "### Pré-processamento das imagens "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbb2Fq_K09zX"
      },
      "source": [
        "def PreProcess(data_dir,target_size,batch_size,shuffle,seed):\n",
        "    \n",
        "    datagen_cnn = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.2)\n",
        "\n",
        "    train_cnn = datagen_cnn.flow_from_directory(data_dir,\n",
        "                                          class_mode = \"categorical\",\n",
        "                                          target_size = target_size,\n",
        "                                          color_mode=\"rgb\",\n",
        "                                          batch_size = batch_size, \n",
        "                                          shuffle = shuffle,\n",
        "                                          subset='training',\n",
        "                                          seed = seed)\n",
        "\n",
        "    validation_cnn = datagen_cnn.flow_from_directory(data_dir,\n",
        "                                          class_mode = \"categorical\",\n",
        "                                          target_size = target_size,\n",
        "                                          color_mode=\"rgb\",\n",
        "                                          batch_size = batch_size, \n",
        "                                          shuffle = shuffle,\n",
        "                                          subset='validation',\n",
        "                                          seed = seed)\n",
        "\n",
        "    return train_cnn, validation_cnn "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSxtv_xt0kpB"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUACoLEQF3rz"
      },
      "source": [
        "A saída de cada camada Conv2D e MaxPooling2D é um tensor 3D de forma (altura, largura, canais). As dimensões de altura e largura tendem a diminuir à medida que você se aprofunda na rede. O número de canais de saída para cada camada Conv2D é controlado pelo primeiro argumento (por exemplo, 32 ou 64). Normalmente, à medida que a largura e a altura diminuem, você pode (computacionalmente) adicionar mais canais de saída em cada camada Conv2D."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wzgfClBCqoV"
      },
      "source": [
        "### Modelo de CNN "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ruv4xxGP6L"
      },
      "source": [
        "As linhas de código abaixo definir a base convolucional utilizando um padrão comum: uma pilha de Conv2D e MaxPooling2D camadas.\n",
        "\n",
        "Como entrada, um CNN assume tensores de forma (image_height, image_width, color_channels), ignorando o tamanho do lote. O color_channels se refere a (R, G, B). A CNN foi configuradapara processar entradas de forma (768, 768, 3), que é o formato de imagens lung_image_sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Owmt1_ci-m0"
      },
      "source": [
        "def Model_CNN():\n",
        "  model = models.Sequential()\n",
        "\n",
        "  # BatchNormalization()(inp) testar o BatchNormalization\n",
        "  # Block 1\n",
        "  model.add(layers.BatchNormalization(input_shape=(768, 768, 3)))\n",
        "  # model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv1', input_shape=(768, 768, 3))) # Original\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv1'))\n",
        "  model.add(layers.Conv2D(32, (1, 1), activation='relu',name='block1_conv2'))\n",
        "  model.add(layers.MaxPooling2D((2, 2),strides=(2, 2), name='block1_pool'))\n",
        "\n",
        "  # Block 2\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', name='block2_conv1'))\n",
        "  model.add(layers.Conv2D(64, (1, 1), activation='relu',name='block2_conv2'))\n",
        "  model.add(layers.MaxPooling2D((2, 2),strides=(2, 2), name='block2_pool'))\n",
        "\n",
        "  # Block 3\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu',name='block3_conv1'))\n",
        "  model.add(layers.Conv2D(128, (1, 1), activation='relu',name='block3_conv2'))\n",
        "  model.add(layers.MaxPooling2D((2, 2),strides=(2, 2), name='block3_pool'))\n",
        "\n",
        "  # Block 4\n",
        "  model.add(layers.Conv2D(256, (3, 3), activation='relu',name='block4_conv1'))\n",
        "  model.add(layers.Conv2D(256, (1, 1), activation='relu',name='block4_conv2'))\n",
        "  model.add(layers.MaxPooling2D((2, 2),strides=(2, 2), name='block4_pool'))\n",
        "\n",
        "  # Block 5\n",
        "  model.add(layers.Conv2D(512, (3, 3), activation='relu',name='block5_conv1'))\n",
        "  model.add(layers.Conv2D(512, (1, 1), activation='relu',name='block5_conv2'))\n",
        "  model.add(layers.MaxPooling2D((2, 2),strides=(2, 2), name='block5_pool'))\n",
        "\n",
        "  # Flatten\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0quSU-YgGhgn"
      },
      "source": [
        "As (768, 768, 64) saídas serão achatadas em vetores de forma (387) antes de passar por duas camadas densas.\n",
        "\n",
        "Para completar o modelo, o último tensor de saída da base convolucional (de formato (4, 4, 64)) em uma ou mais camadas Densas para realizar a classificação. Camadas densas recebem vetores como entrada (que são 1D), enquanto a saída atual é um tensor 3D. Primeiro, você nivelará (ou desenrolará) a saída 3D em 1D e, em seguida, adicionará uma ou mais camadas Densas na parte superior. O conjunto tem 3 classes de saída, então você usa uma camada Densa final com 3 saídas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZKGXxHhCv0s"
      },
      "source": [
        "### Função para compilar o modelo da CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pulpavwaDk0m"
      },
      "source": [
        "def Compile_Model_CNN(loss, optimizer_cnn, metrics):\n",
        "  model_cnn = Model_CNN()\n",
        "  model_cnn.compile(loss=loss, optimizer=optimizer_cnn, metrics=[metrics])\n",
        "  return model_cnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr7E0_4DC20D"
      },
      "source": [
        "### Função de treinamento da CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAJ7-eRj2bHg"
      },
      "source": [
        "def Train_Model_CNN(model_cnn, train_cnn, nb_epoch, validation_cnn):\n",
        "    model_cnn.fit(train_cnn, epochs = nb_epoch,  validation_data=validation_cnn)\n",
        "\n",
        "    # salvar modelo para posterior avaliação      \n",
        "    model_json = model_cnn.to_json()\n",
        "    model_name = \"Modelo_CNN\"\n",
        "    with open('/content/drive/MyDrive/'+model_name+\".json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    model_cnn.save_weights('/content/drive/MyDrive/'+model_name+'.h5')\n",
        "    \n",
        "    return model_cnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj0ighk2C-D9"
      },
      "source": [
        "### Função para execução da CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5x3cr4BY7oW"
      },
      "source": [
        "def Execute_Model_CNN():\n",
        "  train_cnn, validation_cnn = PreProcess(data_dir,target_size,batch_size,shuffle,seed)\n",
        "  model_cnn = Compile_Model_CNN(loss, optimizer_cnn, metrics)\n",
        "  model_cnn.summary()\n",
        "  history_cnn = Train_Model_CNN(model_cnn, train_cnn, nb_epoch, validation_cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApFgSRgHDIPU"
      },
      "source": [
        "### Função para avaliação  da CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTtM4Q_J3F4C"
      },
      "source": [
        "def Evaluate_Model_CNN():\n",
        "\n",
        "    train_cnn, validation_cnn = PreProcess(data_dir,target_size,batch_size,shuffle,seed)\n",
        "\n",
        "    # Recuperando o modelo Treinado da CNN\n",
        "    with open('/content/drive/MyDrive/Modelo_CNN.json','r') as modelo:\n",
        "      json = modelo.read()\n",
        "    model_cnn = model_from_json(json)\n",
        "\n",
        "    # Recuperando os pesos do treinamento da CNN\n",
        "    model_cnn.load_weights('/content/drive/MyDrive/Modelo_CNN.h5') \n",
        "\n",
        "    # predicted_cnn = model_cnn.predict(validation_cnn)\n",
        "\n",
        "    # Y_pred = model_cnn.predict_generator(validation_cnn, steps=4500 // batchsize+1)\n",
        "    Y_pred = model_cnn.predict(validation_cnn)\n",
        "    y_pred = np.argmax(Y_pred, axis=1)\n",
        "    \n",
        "    print('\\nMatriz de Confusão')\n",
        "    print(confusion_matrix(validation_cnn.classes, y_pred),'\\n')\n",
        "\n",
        "    print(\" ---- F1 Score ----\")\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'weighted'),'\\n')\n",
        "\n",
        "    print(\" ---- Recall ----\")\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'weighted'),'\\n')\n",
        "    \n",
        "    print(\" ---- Precision ----\")\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'micro', zero_division=1))\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'macro', zero_division=1))\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'weighted', zero_division=1),'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BuGcrBcDLz7"
      },
      "source": [
        "### Chamada para execução da CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbF9sxmW3nIN",
        "outputId": "46addf91-4097-4ae5-d092-7202655792b8"
      },
      "source": [
        "Execute_Model_CNN()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 120 images belonging to 3 classes.\n",
            "Found 30 images belonging to 3 classes.\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_12 (Batc (None, 768, 768, 3)       12        \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 768, 768, 32)      896       \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 768, 768, 32)      1056      \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 384, 384, 32)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 382, 382, 64)      18496     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 382, 382, 64)      4160      \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 191, 191, 64)      0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 189, 189, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 189, 189, 128)     16512     \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 94, 94, 128)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 92, 92, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 92, 92, 256)       65792     \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 46, 46, 256)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 44, 44, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 44, 44, 512)       262656    \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 22, 22, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 247808)            0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 512)               126878208 \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 128,961,583\n",
            "Trainable params: 128,961,577\n",
            "Non-trainable params: 6\n",
            "_________________________________________________________________\n",
            "30/30 [==============================] - 7s 220ms/step - loss: 1.6971 - accuracy: 0.2914 - val_loss: 1.1010 - val_accuracy: 0.3333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruCjC2bMDPr-"
      },
      "source": [
        "### Chamada para avaliação da CNN\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zYrxTys3pPe",
        "outputId": "3395991c-fa93-4a72-ad8d-94d218e137d4"
      },
      "source": [
        "Evaluate_Model_CNN()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 120 images belonging to 3 classes.\n",
            "Found 30 images belonging to 3 classes.\n",
            "\n",
            "Matriz de Confusão\n",
            "[[ 0  0 10]\n",
            " [ 0  0 10]\n",
            " [ 0  0 10]] \n",
            "\n",
            " ---- F1 Score ----\n",
            "0.3333333333333333\n",
            "0.16666666666666666\n",
            "0.16666666666666666 \n",
            "\n",
            " ---- Recall ----\n",
            "0.3333333333333333\n",
            "0.3333333333333333\n",
            "0.3333333333333333 \n",
            "\n",
            " ---- Precision ----\n",
            "0.3333333333333333\n",
            "0.7777777777777778\n",
            "0.7777777777777778 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR-_ob8w0szO"
      },
      "source": [
        "# VGG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Km_PHpFECl4"
      },
      "source": [
        "### Modelo VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBVnHogyt6y9"
      },
      "source": [
        "def Model_VGG():\n",
        "  model = VGG16(include_top=False, input_shape=(768, 768, 3))\n",
        "\n",
        "  for layer in model.layers:\n",
        "   layer.trainable = False\n",
        "  \n",
        "  flat1 = Flatten()(model.layers[-1].output)\n",
        "  class1 = Dense(1024, activation='relu')(flat1)\n",
        "  class2 = Dense(512, activation='relu')(class1)\n",
        "  class3 = Dense(256, activation='relu')(class2)\n",
        "  class4 = Dense(128, activation='relu')(class3)\n",
        "  output = Dense(3, activation='softmax')(class4)\n",
        "\n",
        "  model = Model(inputs=model.inputs, outputs=output)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoMX8WVPD-ll"
      },
      "source": [
        "### Função para compilar o modelo da VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KdWBQjDlur9"
      },
      "source": [
        "def Compile_Model_VGG(loss, optimizer_cnn, metrics):\n",
        "  \n",
        "  model_vgg = Model_VGG()\n",
        "  model_vgg.compile(loss=loss, optimizer=optimizer_cnn, metrics=[metrics])\n",
        "  \n",
        "  return model_vgg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkL4_aCdD570"
      },
      "source": [
        "### Função de treinamento da VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I67NDqig2fYw"
      },
      "source": [
        "def Train_Model_VGG(model_vgg, train_cnn, nb_epoch, validation_cnn):\n",
        "     \n",
        "     model_vgg.fit(train_cnn, epochs = nb_epoch,  validation_data=validation_cnn)\n",
        "\n",
        "     # salvar modelo para posterior avaliação      \n",
        "     model_json = model_vgg.to_json()\n",
        "     model_name = \"Modelo_VGG\"\n",
        "     with open('/content/drive/MyDrive/'+model_name+\".json\", \"w\") as json_file:\n",
        "      json_file.write(model_json)\n",
        "     model_vgg.save_weights('/content/drive/MyDrive/'+model_name+'.h5')\n",
        "\n",
        "     return model_vgg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_8aLwEiDtqZ"
      },
      "source": [
        "### Função para execução da VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAp8s5ZQ2yQB"
      },
      "source": [
        "def Execute_Model_VGG():\n",
        "  \n",
        "  train_cnn, validation_cnn = PreProcess(data_dir,target_size,batch_size,shuffle,seed)\n",
        "  model_vgg = Compile_Model_VGG(loss, optimizer_cnn, metrics)\n",
        "  model_vgg.summary()\n",
        "  history_cnn = Train_Model_VGG(model_vgg, train_cnn, nb_epoch, validation_cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxY-SCSQDxOw"
      },
      "source": [
        "### Função para avaliação  da VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Md9FUi21t0"
      },
      "source": [
        "def Evaluate_Model_VGG():\n",
        "\n",
        "    train_cnn, validation_cnn = PreProcess(data_dir,target_size,batch_size,shuffle,seed)\n",
        "\n",
        "    # Recuperando o modelo Treinado da CNN\n",
        "    with open('/content/drive/MyDrive/Modelo_VGG.json','r') as modelo:\n",
        "      json = modelo.read()\n",
        "    model_vgg = model_from_json(json)\n",
        "\n",
        "    # Recuperando os pesos do treinamento da CNN\n",
        "    model_vgg.load_weights('/content/drive/MyDrive/Modelo_VGG.h5') \n",
        "\n",
        "    Y_pred = model_vgg.predict(validation_cnn)\n",
        "    y_pred = np.argmax(Y_pred, axis=1)\n",
        "    \n",
        "    print('\\nMatriz de Confusão')\n",
        "    print(confusion_matrix(validation_cnn.classes, y_pred),'\\n')\n",
        "\n",
        "    print(\" ---- F1 Score ----\")\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'weighted'),'\\n')\n",
        "\n",
        "    print(\" ---- Recall ----\")\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'weighted'),'\\n')\n",
        "    \n",
        "    print(\" ---- Precision ----\")\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'weighted', zero_division=1),'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-AlwkIODgbb"
      },
      "source": [
        "### Chamada para execução da VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpfw8xnX3h3x",
        "outputId": "53cc33f1-fc48-498f-9bff-0c79ac68faf7"
      },
      "source": [
        "Execute_Model_VGG()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 120 images belonging to 3 classes.\n",
            "Found 30 images belonging to 3 classes.\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 768, 768, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 768, 768, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 768, 768, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 384, 384, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 384, 384, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 384, 384, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 192, 192, 128)     0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 192, 192, 256)     295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 192, 192, 256)     590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 192, 192, 256)     590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 96, 96, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 96, 96, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 96, 96, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 96, 96, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 48, 48, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 48, 48, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 48, 48, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 48, 48, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 24, 24, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 294912)            0         \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 1024)              301990912 \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 317,395,011\n",
            "Trainable params: 302,680,323\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "30/30 [==============================] - 12s 372ms/step - loss: 126.1744 - accuracy: 0.5086 - val_loss: 9.0931 - val_accuracy: 0.7333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvVQ4eNqDWID"
      },
      "source": [
        "### Chamada para avaliação da VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roJheMrn3sbX",
        "outputId": "01abe81f-e48c-414b-ad09-929f28cce482"
      },
      "source": [
        "Evaluate_Model_VGG()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 120 images belonging to 3 classes.\n",
            "Found 30 images belonging to 3 classes.\n",
            "\n",
            "Matriz de Confusão\n",
            "[[5 3 2]\n",
            " [4 3 3]\n",
            " [3 4 3]] \n",
            "\n",
            " ---- F1 Score ----\n",
            "0.36666666666666664\n",
            "0.36262626262626263\n",
            "0.3626262626262626 \n",
            "\n",
            " ---- Recall ----\n",
            "0.36666666666666664\n",
            "0.3666666666666667\n",
            "0.36666666666666664 \n",
            "\n",
            " ---- Precision ----\n",
            "0.36666666666666664\n",
            "0.36388888888888893\n",
            "0.36388888888888893 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTV_f7Ga0ukn"
      },
      "source": [
        "# SqueezeNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owghqPlyEF9E"
      },
      "source": [
        "### Modelo SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNGdcVZE0zfT"
      },
      "source": [
        "sq1x1 = \"squeeze1x1\"\n",
        "exp1x1 = \"expand1x1\"\n",
        "exp3x3 = \"expand3x3\"\n",
        "relu = \"relu_\"\n",
        "\n",
        "WEIGHTS_PATH = \"https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels.h5\"\n",
        "WEIGHTS_PATH_NO_TOP = \"https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "\n",
        "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
        "    s_id = 'fire' + str(fire_id) + '/'\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = 3\n",
        "    \n",
        "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
        "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
        "\n",
        "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
        "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
        "\n",
        "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
        "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
        "\n",
        "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
        "    return x\n",
        "\n",
        "\n",
        "def Model_SqzNet(include_top=True, weights='imagenet', \n",
        "               input_tensor=None, input_shape=None,\n",
        "               pooling=None,\n",
        "               use_bn_on_input = False,\n",
        "               classes=1000):\n",
        "    \"\"\"Instantiates the SqueezeNet architecture.\n",
        "    \"\"\"\n",
        "        \n",
        "    if weights not in {'imagenet', None}:\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `imagenet` '\n",
        "                         '(pre-training on ImageNet).')\n",
        "\n",
        "    if weights == 'imagenet' and classes != 1000:\n",
        "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=227,\n",
        "                                      min_size=48,\n",
        "                                      data_format=K.image_data_format(),\n",
        "                                      require_flatten=include_top)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        raw_img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if use_bn_on_input:\n",
        "        img_input = BatchNormalization()(raw_img_input)\n",
        "    else:\n",
        "        img_input = raw_img_input\n",
        "\n",
        "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
        "    x = Activation('relu', name='relu_conv1')(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
        "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
        "\n",
        "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
        "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
        "\n",
        "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
        "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
        "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
        "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
        "    \n",
        "    if include_top:\n",
        "    \n",
        "        x = Dropout(0.5, name='drop9')(x)\n",
        "\n",
        "        x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
        "        x = Activation('relu', name='relu_conv10')(x)\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Activation('softmax', name='loss')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling=='max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "        elif pooling==None:\n",
        "            pass\n",
        "        else:\n",
        "            raise ValueError(\"Unknown argument for 'pooling'=\" + pooling)\n",
        "\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "\n",
        "    model = Model(inputs, x, name='squeezenet')\n",
        "\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                                    WEIGHTS_PATH,\n",
        "                                    cache_subdir='models')\n",
        "        else:\n",
        "            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                                    WEIGHTS_PATH_NO_TOP,\n",
        "                                    cache_subdir='models')\n",
        "            \n",
        "        model.load_weights(weights_path)\n",
        "        if K.backend() == 'theano':\n",
        "            layer_utils.convert_all_kernels_in_model(model)\n",
        "\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "\n",
        "            if K.backend() == 'tensorflow':\n",
        "                print('You are using the TensorFlow backend, yet you '\n",
        "                              'are using the Theano '\n",
        "                              'image data format convention '\n",
        "                              '(`image_data_format=\"channels_first\"`). '\n",
        "                              'For best performance, set '\n",
        "                              '`image_data_format=\"channels_last\"` in '\n",
        "                              'your Keras config '\n",
        "                              'at ~/.keras/keras.json.')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQxas_T8EpAT"
      },
      "source": [
        "### Função para compilar o modelo da SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P445-sYxlwMu"
      },
      "source": [
        "def Compile_Model_SqzNet(input_shape, nb_class, loss, optimizer_sn, metrics):\n",
        "  model_sn = Model_SqzNet(input_shape=input_shape,  weights=None, classes = nb_class)\n",
        "  sgd = SGD(lr=0.001, decay=0.0002, momentum=0.9, nesterov=True)\n",
        "  model_sn.compile(loss=loss, optimizer=optimizer_sn, metrics=[metrics])\n",
        "  return model_sn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6co5yNMElFk"
      },
      "source": [
        "### Função para treinamento  da SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH-cEMiO2_wQ"
      },
      "source": [
        "def Train_Model_SqzNet(model_sn, train_cnn, nb_epoch, validation_cnn):\n",
        "    model_sn.fit(train_cnn, epochs = nb_epoch,  validation_data=validation_cnn)\n",
        "\n",
        "    # salvar modelo para posterior avaliação      \n",
        "    model_json = model_sn.to_json()\n",
        "    model_name = \"Modelo_SqzNet\"\n",
        "    with open('/content/drive/MyDrive/'+model_name+\".json\", \"w\") as json_file:\n",
        "      json_file.write(model_json)\n",
        "    model_sn.save_weights('/content/drive/MyDrive/'+model_name+'.h5')\n",
        "\n",
        "    return model_sn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzr9rgQbEcNq"
      },
      "source": [
        "### Função para execuação  da SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAOX9uo3mFBm"
      },
      "source": [
        "def Execute_Model_SqzNet():\n",
        "  train_cnn, validation_cnn = PreProcess(data_dir,target_size,batch_size,shuffle,seed)\n",
        "  model_sn = Compile_Model_SqzNet(input_shape, nb_class, loss, optimizer_sn, metrics)\n",
        "  model_sn.summary()\n",
        "  history_sn = Train_Model_SqzNet(model_sn, train_cnn, nb_epoch, validation_cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUwsp1iWEbBU"
      },
      "source": [
        "### Função para avaliação  da SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5wa7dZ229Za"
      },
      "source": [
        "def Evaluate_Model_SqzNet():\n",
        "    \n",
        "    train_cnn, validation_cnn = PreProcess(data_dir,target_size,batch_size,shuffle,seed)\n",
        "\n",
        "    # Recuperando o modelo Treinado da CNN\n",
        "    with open('/content/drive/MyDrive/Modelo_SqzNet.json','r') as modelo:\n",
        "      json = modelo.read()\n",
        "    model_vgg = model_from_json(json)\n",
        "\n",
        "    # Recuperando os pesos do treinamento da CNN\n",
        "    model_vgg.load_weights('/content/drive/MyDrive/Modelo_SqzNet.h5') \n",
        "\n",
        "    Y_pred = model_vgg.predict(validation_cnn)\n",
        "    y_pred = np.argmax(Y_pred, axis=1)\n",
        "    \n",
        "    print('\\nMatriz de Confusão')\n",
        "    print(confusion_matrix(validation_cnn.classes, y_pred),'\\n')\n",
        "\n",
        "    print(\" ---- F1 Score ----\")\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(f1_score(validation_cnn.classes, y_pred, average = 'weighted'),'\\n')\n",
        "\n",
        "    print(\" ---- Recall ----\")\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'micro'))\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'macro'))\n",
        "    print(recall_score(validation_cnn.classes, y_pred, average = 'weighted'),'\\n')\n",
        "    \n",
        "    print(\" ---- Precision ----\")\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'micro', zero_division=1))\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'macro', zero_division=1))\n",
        "    print(precision_score(validation_cnn.classes, y_pred, average = 'weighted', zero_division=1),'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n67p6KcnETjh"
      },
      "source": [
        "### Chamada para execução da SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDJ6IHafy6d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66742653-b7f6-420d-86e4-98a56ea94d9f"
      },
      "source": [
        "Execute_Model_SqzNet()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 120 images belonging to 3 classes.\n",
            "Found 30 images belonging to 3 classes.\n",
            "Model: \"squeezenet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           [(None, 768, 768, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 383, 383, 64) 1792        input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "relu_conv1 (Activation)         (None, 383, 383, 64) 0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 191, 191, 64) 0           relu_conv1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "fire2/squeeze1x1 (Conv2D)       (None, 191, 191, 16) 1040        pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "fire2/relu_squeeze1x1 (Activati (None, 191, 191, 16) 0           fire2/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire2/expand1x1 (Conv2D)        (None, 191, 191, 64) 1088        fire2/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire2/expand3x3 (Conv2D)        (None, 191, 191, 64) 9280        fire2/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire2/relu_expand1x1 (Activatio (None, 191, 191, 64) 0           fire2/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire2/relu_expand3x3 (Activatio (None, 191, 191, 64) 0           fire2/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire2/concat (Concatenate)      (None, 191, 191, 128 0           fire2/relu_expand1x1[0][0]       \n",
            "                                                                 fire2/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire3/squeeze1x1 (Conv2D)       (None, 191, 191, 16) 2064        fire2/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire3/relu_squeeze1x1 (Activati (None, 191, 191, 16) 0           fire3/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire3/expand1x1 (Conv2D)        (None, 191, 191, 64) 1088        fire3/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire3/expand3x3 (Conv2D)        (None, 191, 191, 64) 9280        fire3/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire3/relu_expand1x1 (Activatio (None, 191, 191, 64) 0           fire3/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire3/relu_expand3x3 (Activatio (None, 191, 191, 64) 0           fire3/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire3/concat (Concatenate)      (None, 191, 191, 128 0           fire3/relu_expand1x1[0][0]       \n",
            "                                                                 fire3/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3 (MaxPooling2D)            (None, 95, 95, 128)  0           fire3/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire4/squeeze1x1 (Conv2D)       (None, 95, 95, 32)   4128        pool3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "fire4/relu_squeeze1x1 (Activati (None, 95, 95, 32)   0           fire4/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire4/expand1x1 (Conv2D)        (None, 95, 95, 128)  4224        fire4/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire4/expand3x3 (Conv2D)        (None, 95, 95, 128)  36992       fire4/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire4/relu_expand1x1 (Activatio (None, 95, 95, 128)  0           fire4/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire4/relu_expand3x3 (Activatio (None, 95, 95, 128)  0           fire4/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire4/concat (Concatenate)      (None, 95, 95, 256)  0           fire4/relu_expand1x1[0][0]       \n",
            "                                                                 fire4/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire5/squeeze1x1 (Conv2D)       (None, 95, 95, 32)   8224        fire4/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire5/relu_squeeze1x1 (Activati (None, 95, 95, 32)   0           fire5/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire5/expand1x1 (Conv2D)        (None, 95, 95, 128)  4224        fire5/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire5/expand3x3 (Conv2D)        (None, 95, 95, 128)  36992       fire5/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire5/relu_expand1x1 (Activatio (None, 95, 95, 128)  0           fire5/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire5/relu_expand3x3 (Activatio (None, 95, 95, 128)  0           fire5/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire5/concat (Concatenate)      (None, 95, 95, 256)  0           fire5/relu_expand1x1[0][0]       \n",
            "                                                                 fire5/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool5 (MaxPooling2D)            (None, 47, 47, 256)  0           fire5/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire6/squeeze1x1 (Conv2D)       (None, 47, 47, 48)   12336       pool5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "fire6/relu_squeeze1x1 (Activati (None, 47, 47, 48)   0           fire6/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire6/expand1x1 (Conv2D)        (None, 47, 47, 192)  9408        fire6/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire6/expand3x3 (Conv2D)        (None, 47, 47, 192)  83136       fire6/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire6/relu_expand1x1 (Activatio (None, 47, 47, 192)  0           fire6/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire6/relu_expand3x3 (Activatio (None, 47, 47, 192)  0           fire6/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire6/concat (Concatenate)      (None, 47, 47, 384)  0           fire6/relu_expand1x1[0][0]       \n",
            "                                                                 fire6/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire7/squeeze1x1 (Conv2D)       (None, 47, 47, 48)   18480       fire6/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire7/relu_squeeze1x1 (Activati (None, 47, 47, 48)   0           fire7/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire7/expand1x1 (Conv2D)        (None, 47, 47, 192)  9408        fire7/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire7/expand3x3 (Conv2D)        (None, 47, 47, 192)  83136       fire7/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire7/relu_expand1x1 (Activatio (None, 47, 47, 192)  0           fire7/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire7/relu_expand3x3 (Activatio (None, 47, 47, 192)  0           fire7/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire7/concat (Concatenate)      (None, 47, 47, 384)  0           fire7/relu_expand1x1[0][0]       \n",
            "                                                                 fire7/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire8/squeeze1x1 (Conv2D)       (None, 47, 47, 64)   24640       fire7/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire8/relu_squeeze1x1 (Activati (None, 47, 47, 64)   0           fire8/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire8/expand1x1 (Conv2D)        (None, 47, 47, 256)  16640       fire8/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire8/expand3x3 (Conv2D)        (None, 47, 47, 256)  147712      fire8/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire8/relu_expand1x1 (Activatio (None, 47, 47, 256)  0           fire8/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire8/relu_expand3x3 (Activatio (None, 47, 47, 256)  0           fire8/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire8/concat (Concatenate)      (None, 47, 47, 512)  0           fire8/relu_expand1x1[0][0]       \n",
            "                                                                 fire8/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire9/squeeze1x1 (Conv2D)       (None, 47, 47, 64)   32832       fire8/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire9/relu_squeeze1x1 (Activati (None, 47, 47, 64)   0           fire9/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire9/expand1x1 (Conv2D)        (None, 47, 47, 256)  16640       fire9/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire9/expand3x3 (Conv2D)        (None, 47, 47, 256)  147712      fire9/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire9/relu_expand1x1 (Activatio (None, 47, 47, 256)  0           fire9/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire9/relu_expand3x3 (Activatio (None, 47, 47, 256)  0           fire9/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire9/concat (Concatenate)      (None, 47, 47, 512)  0           fire9/relu_expand1x1[0][0]       \n",
            "                                                                 fire9/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "drop9 (Dropout)                 (None, 47, 47, 512)  0           fire9/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv10 (Conv2D)                 (None, 47, 47, 3)    1539        drop9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu_conv10 (Activation)        (None, 47, 47, 3)    0           conv10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_5 (Glo (None, 3)            0           relu_conv10[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "loss (Activation)               (None, 3)            0           global_average_pooling2d_5[0][0] \n",
            "==================================================================================================\n",
            "Total params: 724,035\n",
            "Trainable params: 724,035\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "30/30 [==============================] - 8s 241ms/step - loss: 1.0993 - accuracy: 0.3202 - val_loss: 1.0987 - val_accuracy: 0.3333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_pKf6nfEM7l"
      },
      "source": [
        "### Chamada para avaliação da SqueezeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q88gD9E3yoX",
        "outputId": "610ddc8e-57cb-4916-ebc3-f49aa86e1c24"
      },
      "source": [
        "Evaluate_Model_SqzNet()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 120 images belonging to 3 classes.\n",
            "Found 30 images belonging to 3 classes.\n",
            "\n",
            "Matriz de Confusão\n",
            "[[10  0  0]\n",
            " [10  0  0]\n",
            " [10  0  0]] \n",
            "\n",
            " ---- F1 Score ----\n",
            "0.3333333333333333\n",
            "0.16666666666666666\n",
            "0.16666666666666666 \n",
            "\n",
            " ---- Recall ----\n",
            "0.3333333333333333\n",
            "0.3333333333333333\n",
            "0.3333333333333333 \n",
            "\n",
            " ---- Precision ----\n",
            "0.3333333333333333\n",
            "0.7777777777777777\n",
            "0.7777777777777778 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}